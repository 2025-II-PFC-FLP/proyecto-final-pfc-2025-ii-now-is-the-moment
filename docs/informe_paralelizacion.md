# Informe de Paralelizaci贸n

## 1. Estrategia de paralelizaci贸n aplicada

Tomamos como punto de partida la versi贸n secuencial del
problema, la cual eval煤a todas las permutaciones posibles de la
programaci贸n de riego y, para cada permutaci贸n, calcula dos costos
independientes:

1.  **Costo de riego de los tablones**\
2.  **Costo de movilidad entre tablones consecutivos**

Ambos costos pueden evaluarse por separado y luego sumarse para obtener
el costo total de la programaci贸n. A partir de 茅sto identificamos:

---

### a) Paralelizaci贸n del c谩lculo del costo por tabl贸n (`costoRiegoFinca`)

El costo total del riego se obtiene sumando el costo de cada tabl贸n:

``` scala
indices.par.map(i => costoRiegoTablon(i, f, pi)).sum
```

Cada tabl贸n puede ser evaluado de manera independiente, porque el c谩lculo interno depende solo de:

-   sus par谩metros propios (`tsup`, `treg`, `prio`)
-   el vector de tiempos de inicio `tIR(f, pi)` ya calculado antes

No existe dependencia entre tablones, por lo que esta parte nos permite hacer la paralelizaci贸n para los costos por tabl贸n.

---

### b) Paralelizaci贸n sobre las permutaciones (`ProgramacionRiegoOptimo`)

Este es el punto m谩s costoso de toda la ejecuci贸n donde primero se generan todas las permutaciones:

``` scala
val todas = indices.permutations.map(_.toVector).toVector
```

Luego, cada permutaci贸n puede evaluarse de forma independiente:

``` scala
todas.par.map { pi =>
  val cr = costoRiegoFinca(f, pi)
  val cm = costoMovilidad(f, pi, d)
  (pi, cr + cm)
}
```

Esto es un patr贸n *map-reduce*:\
- *map paralelo* para evaluar cada permutaci贸n\
- *reduce secuencial* para seleccionar la de menor costo

---

## 2. Partes que permanecen secuenciales

### a) C谩lculo de `tIR`

El inicio de riego del tabl贸n *j* depende del final del tabl贸n *j-1*, lo cual introduce una dependencia estrictamente secuencial.

### b) Selecci贸n del m铆nimo

La operaci贸n `minBy` es secuencial, pero el costo es peque帽o comparado con la fase paralela.

---

## 3. Aplicaci贸n de la Ley de Amdahl

La ley de Amdahl muestra que la aceleraci贸n m谩xima depende de la proporci贸n paralelizable del programa:

\[ S = `\frac{1}{(1 - p) + \frac{p}{N}}`{=tex} \]

Donde:
 = proporci贸n paralelizable\
 = n煤mero de n煤cleos\
 = aceleraci贸n m谩xima posible

-   La parte paralelizable: evaluaci贸n de permutaciones y costos\
-   La parte secuencial: c谩lculo de `tIR`, generaci贸n de permutaciones y reducci贸n final

Esto explica los resultados obtenidos:

  Tama帽o finca   Secuencial (ms)   Paralela (ms)   Aceleraci贸n
  ------------- ----------------- --------------- ---------------
  10             120               80              33.33%
  20             500               300             40.00%
  30             1200              700             41.67%

### Interpretaci贸n

-   Para tama帽os peque帽os (10 tablones)
El tiempo secuencial fijo influye m谩s.
La Aceleraci贸n es menor (33%).

-   Para tama帽os medianos y grandes (20-30 tablones)
La parte paralelizable crece much铆simo (evaluar m谩s permutaciones).
La aceleraci贸n aumenta progresivamente (40-42%).

-   La aceleraci贸n no llega al 100%
Como predice Amdahl, el componente secuencial pone un l铆mite natural.
Incluso con m谩s n煤cleos, la aceleraci贸n se estabilizar铆a porque tIR y la reducci贸n final no pueden paralelizarse.

---

## 4. Conclusiones

-   La paralelizaci贸n es efectiva gracias a la independencia entre permutaciones y entre tablones individuales.
-   El c谩lculo secuencial de `tIR` impone un l铆mite natural seg煤n Amdahl.
-   Las mediciones concuerdan correctamente con el comportamiento esperado de un programa con alta fracci贸n paralelizable pero no completamente libre de dependencias.
